import os
import csv
import time
import numpy
import array
import pandas
import ntpath
from multiprocessing import Pool
import multiprocessing
import subprocess as sub
from optparse import OptionParser
from collections import defaultdict

global documentFrequency

def disasm_file(target_file):
	try:
		os.system("dumpbin\\dumpbin /disasm:nobytes \"" + target_file + "\" > \"" + target_file + ".csv\"")	
		
		return 1
		
	except Exception as e: 
		print (e)
		print ("ERROR: disasm_file FILE - " + target_file)
		return 0

def opcode_3gram(target_file):
	try:
		if (os.path.isfile(target_file)):
			openfile = open(target_file)
			infile = openfile.readlines()[8:-8]
			openfile.close()

			writer = open(target_file, "w")

			lines = []
			
			for inline in infile:
				inline = str(inline[2:])
				
				if len(inline.split()) > 1:
					inline = inline.split(' ' , 1)[1]			
					if len(inline.split()) > 1:
						inline, line_b = inline.split(' ' , 1)
						inline = inline + '\n'
						lines.append(inline)
					else:
						lines.append(inline)
					
			for i in range(0, len(lines)):
				if lines[i] is lines[-1]:
					break
					
				if lines[i + 1] is lines[-1]:
					break
					
				if lines[i + 2] is lines[-1]:
					break

				line = lines[i]
				line2 = lines[i+1]
				line3 = lines[i+2]
				line4 = lines[i+3]
				
				#writer.write("\"" + line.replace('\n', '\"\n'))
				#writer.write("\"" + line.replace('\n', '|') + line2.replace('\n', '\"\n'))
				#writer.write("\"" + line.replace('\n', '|') + line2.replace('\n', '|') + line3.replace('\n', '\"\n'))
				writer.write("\"" + line.replace('\n', '|') + line2.replace('\n', '|') + line3.replace('\n', '|') + line4.replace('\n', '\"\n'))

				#if line is lines[-1]:
				#	break
				
				#if line2 is lines[-1]:
				#	break
				
				#if line3 is lines[-1]:
				#	break
				
				if line4 is lines[-1]:
					break

			writer.close()
			
			return 1
			
	except Exception as e: 
		print (e)
		print ("ERROR: opcode_3gram FILE - " + target_file)
		return 0

	
def opcode_freq(target_file):
	try:
		if (os.path.isfile(target_file)):
			openfile = open(target_file)
			opencsv = csv.reader(openfile)
			
			firstColumn = set()
			firstColumn = defaultdict(int)
			
			for row in opencsv:
				firstColumn[row[0]] += 1

			openfile.close()	
			
			openoutput = open(target_file,'wt', newline='')
			writer = csv.writer(openoutput)
			
			for row in firstColumn.items():
				writer.writerow(row)
				
			openoutput.close()
			
			return 1
			
	except Exception as e: 
		print (e)
		print ("ERROR: opcode_freq FILE - " + target_file)
		return 0
	
	
def feature_extract(target_file):	
	if (disasm_file(target_file) == 0):
		if (os.path.isfile(target_file + ".csv")):
			os.remove(target_file + ".csv")
		return 0

	target_file = target_file + ".csv"
	
	if os.stat(target_file).st_size != 0:
		if (opcode_3gram(target_file) == 0):
			return 0
	else:
		print ("Remove: " + target_file)
		os.remove(target_file)	
		return 0
		
	if os.stat(target_file).st_size != 0:
		if (opcode_freq(target_file) == 0):
			return 0
	else:
		print ("Remove: " + target_file)
		os.remove(target_file)	
		return 0
	
	return 1
	
	
def process(target_file):
	count = 0
	for file_name in target_file:
		file_path = file_name.rstrip()
		if (os.path.isfile(file_path)):
			if (feature_extract(file_path) == 0):
				if (os.path.isfile(file_path + ".csv")):
					os.remove(file_path + ".csv")
				print("Exited: " + file_path)
		count +=1				
		if ((count % 500 == 0) or (count == len(target_file))):
			print (str(multiprocessing.current_process()) + " : " + str(count) + "/" + str(len(target_file)))
				


	
	
def spawn_worker(target_file):
    # Spawn worker processes.
	quart = int(len(target_file)/4)
	train1 = target_file[:quart]
	train2 = target_file[quart:(2*quart)]
	train3 = target_file[(2*quart):(3*quart)]
	#train4 = target_file[(3*quart):(4*quart)]
	#train5 = target_file[(4*quart):(5*quart)]
	train4 = target_file[(3*quart):]

	print("Multiproccessing Started for " + str(len(target_file)) + " number of files.")
	print("Worker Spawned : 6")

	trains = [train1, train2, train3, train4]#,train5, train6]
	p = Pool(4)
	p.map(process, trains)
		
	return 1
	
	
def create_database(file_list, ouput_dataset):
	df = pandas.DataFrame()
	df2 = pandas.DataFrame()
	counter = 0
	indexCount = 0
	tt = time.time()
	
	print (documentFrequency)

	for target_file in file_list:
		target_file = target_file.rstrip()
		if os.path.isfile(target_file + ".csv"):
			try:
				opencsv = open(target_file + ".csv")
				read = pandas.read_csv(opencsv, header=None, index_col=None, error_bad_lines=False)
				opencsv.close()
				read.ix[:,1] = 1
				df = (pandas.concat([read,df]))
				df = df.groupby(df.columns[0]).sum()
				df = df.reset_index()

				counter += 1
				
				if counter % 100 == 0:
					df2 = (pandas.concat([df,df2])) 
					df = pandas.DataFrame()
					df2 = df2.groupby(df2.columns[0]).sum()
					df2 = df2.reset_index()
					
				if ((counter % 100 == 0) or (counter == len(file_list))):
					print(str(counter) + "/" + str(len(file_list)))
					print("--- %s seconds ---" % (time.time() - tt))
					tt = time.time()
					
				if (counter % 1000 == 0):
					df2.to_csv(ouput_dataset + str(indexCount) + ".csv", sep=',', header=False, index=False)
					indexCount += 1
					df2 = pandas.DataFrame()
					
			except Exception as e: 
				print (e)
				print ("ERROR: create_database FILE - " + target_file)
				df = pandas.DataFrame()
					
	print("Conclude Database")
	df2 = (pandas.concat([df,df2]))	
	df2 = df2.groupby(df2.columns[0]).sum()
	df2 = df2.reset_index()
	df2.to_csv(ouput_dataset + str(indexCount) + ".csv", sep=',', header=False, index=False)
	
	tt = time.time()
	
	opencsv = open(ouput_dataset + str(indexCount) + ".csv")
	read = pandas.read_csv(opencsv, header=None)
	opencsv.close()
	
	df = read
	first = 0
	os.remove(ouput_dataset + str(indexCount) + ".csv")
	indexCount -= 1
	
	for i in range(indexCount, -1 ,-1):
		opencsv = open(ouput_dataset + str(i) + ".csv")
		read2 = pandas.read_csv(opencsv, header=None)
		opencsv.close()
		
		df2 = read2
		
		df = (pandas.concat([df2,df]))
		df = df.groupby(df.columns[0]).sum()
		df = df.reset_index()
		os.remove(ouput_dataset + str(i) + ".csv")
		
		print (str(indexCount - i) + "/" + str(indexCount))
		print("--- %s seconds ---" % (time.time() - tt))
		tt = time.time()
	
	
	df = df.sort_values(by=[1], ascending=False)
	df = df.head(n=(int)(documentFrequency))
	
	df.to_csv(ouput_dataset, sep=',', header=False, index=False)
	
	return 1
	
	
def calculate_tfidf(file_list, ouput_dataset):
	df = pandas.DataFrame()	
	df2 = pandas.DataFrame()
	counter = 0
	
	opencsv = open(ouput_dataset)
	read = pandas.read_csv(opencsv, header=None)
	opencsv.close() 
	
	for target_file in file_list:
		target_file = target_file.rstrip()
		if os.path.isfile(target_file + ".csv"):
			try:
				opencsv = open(target_file + ".csv")
				read2 = pandas.read_csv(opencsv, header=None, error_bad_lines=False)
				opencsv.close()
				
				df = read	
				df2 = read2
				
				df = df.set_index(df.ix[:,0])
				df2 = df2.set_index(df2.ix[:,0])
				
				df = pandas.merge(df, df2, left_index=True, right_index=True, how='inner');
				
				df = df.drop(['0_y'], axis = 1)
				df = df.fillna(value = 0)
				
				df['tfidf'] = numpy.log10(500 / (1 + df['1_x'])) * df['1_y']
				
				df = df.drop(['1_y'], axis = 1)
				df = df.drop(['1_x'], axis = 1)
				
				df.to_csv(os.path.dirname(target_file) + "\\test\\" + os.path.basename(target_file) + ".csv", sep=',', header=None, index=False)
				
			except Exception as e: 
				print (e)
				print ("ERROR: calculate_tfidf FILE - " + target_file)
			
			counter += 1
				
			if (counter % 500 == 0 or (counter == len(file_list))):
				print(str(counter) + "/" + str((len(file_list))))
				
	return 1
	
	
def inser_data(file_list, dataset, output):
	df = pandas.DataFrame()	
	df2 = pandas.DataFrame()
	temp = pandas.DataFrame()
	
	counter = 0
	dfcount = 0
	
	opencsv = open(dataset)
	read = pandas.read_csv(opencsv, header=None)
	opencsv.close() 
	
	df = read
	
	df = df.iloc[:, :-1]
	df = df.transpose()
	ins = ['label']
	df.insert(loc=1, column='label', value=ins)			
	df = df.transpose()
	
	temp = df
	
	tt = time.time()
	
	for filename in file_list:	
		filename = filename.rstrip()
		if os.path.isfile(filename + ".csv"):		
			try:
				opencsv2= open(filename + ".csv")
				read2 = pandas.read_csv(opencsv2, header=None)
				opencsv2.close() 
			
				df2 = read2.transpose()
				if ("VirusShare" in filename):
					ins = ['label', 1]
				else:
					ins = ['label', 0]
				df2.insert(loc=1, column='label', value=ins)	
				df2 = df2.transpose()

				df = df.set_index(df.ix[:,0])
				df2 = df2.set_index(df2.ix[:,0])
				
				df = pandas.merge(df, df2, left_index=True, right_index=True, how='left');
				
				df = df.drop(df.ix[:,-2:-1], axis = 1)
				df = df.fillna(value = 0)
			except Exception as e: 
				print (e)
				print ("ERROR: insert_data FILE - " + filename)
			
			counter += 1
			
			
			if ((counter % 500 == 0) or (counter == len(file_list))):
				print(str(counter) + "/" + str((len(file_list))))
				print("--- %s seconds ---" % (time.time() - tt))
				tt = time.time()
				
			if (counter % 250 == 0):
				df.to_csv(output + str(dfcount) + ".csv", sep=',', header=None, index=False)
				dfcount += 1
				df = temp
			
			
	df.to_csv(output + str(dfcount) + ".csv", sep=',', header=None, index=False)
	
	tt = time.time()
	
	opencsv = open(output + str(dfcount) + ".csv")
	read = pandas.read_csv(opencsv, header=None)
	opencsv.close()
	
	df = read
	first = 0
	os.remove(output + str(dfcount) + ".csv")
	dfcount -= 1
	
	for i in range(dfcount, -1 ,-1):
		opencsv = open(output + str(i) + ".csv")
		read2 = pandas.read_csv(opencsv, header=None)
		opencsv.close()
		
		df2 = read2
		
		df = df.set_index(df.ix[:,0])
		df2 = df2.set_index(df2.ix[:,0])
		
		df = pandas.merge(df, df2, left_index=True, right_index=True, how='outer')
		os.remove(output + str(i) + ".csv")
		
		if (first == 0):
			df = df.drop(['0_y'], axis = 1)
			first += 1
		else:
			df = df.drop([0], axis = 1)
		print (str(dfcount - i) + "/" + str(dfcount))
		print("--- %s seconds ---" % (time.time() - tt))
		tt = time.time()
		
	
	df.to_csv(output, sep=',', header=None, index=False)
	
	return 1
	
	
if __name__ == '__main__':
	parser = OptionParser()
	parser.add_option("-i", "--input", dest="inputFileList")
	parser.add_option("-t", "--tableset", dest="outputDatatable")
	parser.add_option("-d", "--dataset", dest="outputDataset")
	parser.add_option("-f", "--frequency", dest="documentFrequency")
	
	(options, args) = parser.parse_args()
	input_file_list = options.inputFileList
	ouput_datatable = options.outputDatatable
	ouput_dataset = options.outputDataset
	document_frequency = options.documentFrequency
	
	start_time = time.time()
	
	fip = open(input_file_list)
	file_list = fip.readlines()
	fip.close()
	
	global documentFrequency
	
	if document_frequency != None:
		documentFrequency = document_frequency
	else:
		documentFrequency = 500
		
	
	if input_file_list != None:
		fip = open(input_file_list)
		file_list = fip.readlines()
		fip.close()
		
		for idx, fname in enumerate(file_list):
			file_list[idx] = fname
		
		func = 0
		
		if (func == 0):
		
			print ("Start Feature Extraction")
			
			if (spawn_worker(file_list) == 1):
				print ("Feature Extraction Completed.")
			else:
				print ("ERROR: Feature Extraction Failed.")

		if (func == 0):
		
			print ("Start Creating Dataset")
		
			if (create_database(file_list, ouput_datatable) == 1):
				print ("Database Created.")
			else:
				print ("ERROR: Failed To Create Database.")
			
		if (func == 0):
			
			print ("Start Calculating TFIDF")
			
			if (calculate_tfidf(file_list, ouput_datatable) == 1):
				print ("TFIDF Calculation Completed.")
			else:
				print ("ERROR: Failed To Calculate TFID.")
			
		if (func == 0):
			
			if (inser_data(file_list, ouput_datatable, ouput_dataset) == 1):
				print ("Insert Data Completed.")
			else:
				print ("ERROR: Failed To Insert Data.")
	else:
		print("ERROR: Input File Not Found.")
		
	
	print("--- %s seconds ---" % (time.time() - start_time))